{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate number and ratio of instances of laughter\n",
    "\n",
    "listFiles = []           #create an empty list named list_files\n",
    "list_laugh_ratio = []\n",
    "list_laugh = []\n",
    "\n",
    "for file in os.listdir(path):       #for every file in the path\n",
    "    #if file.endswith(\"*.txt\"):       #specify certain files\n",
    "        listFiles.append(file)     #save the file's name in the list_files list\n",
    "        file_encoding = 'utf8'\n",
    "        with open(file, encoding=file_encoding, errors = 'ignore') as f:\n",
    "            flines = f.readlines() #reads over each line of the file\n",
    "            words = [] #creates an empty list named words\n",
    "            words_processed = []\n",
    "            laugh_list = []\n",
    "\n",
    "            for line in flines: #for each line of the file\n",
    "                new_words = line.split() #splits the contents of each line according to white space. Now new_words\n",
    "                                         #contains all words within each line \n",
    "                    \n",
    "            words += [word.lower() for word in new_words] #turns all characters to lower case\n",
    "            \n",
    "            for word in words:\n",
    "                if not word.startswith('[=') and not word.endswith(']'):\n",
    "                    words_processed.append(word)   #remove unwanted strings e.g. tuts, coughs. Keeps false starts & unknown words.\n",
    "            \n",
    "            denominator = len(words_processed) #calculate the length og this to normalise by\n",
    "            \n",
    "            laughter = ['[=laughs].', '[=laughs]']\n",
    "           \n",
    "            for word in words:\n",
    "                if word in laughter:\n",
    "                     laugh_list.append(word)\n",
    "                      \n",
    "            n_laughs = len(laugh_list)\n",
    "            \n",
    "            if n_laughs is not 0:\n",
    "                #list_laughter.append(n_laughs)\n",
    "                laugh_ratio = n_laughs/denominator\n",
    "                list_laugh_ratio.append(laugh_ratio)\n",
    "                \n",
    "            else:\n",
    "                #list_laughter.append('0')\n",
    "                list_laugh_ratio.append('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calculate number and ratio of fillers\n",
    "\n",
    "listFiles = []           #create an empty list named list_files\n",
    "list_filler_ratio = []\n",
    "list_fillers = []\n",
    "\n",
    "for file in glob.glob(os.path.join(path, '*.txt')):      #for every file in the path\n",
    "    #if file.endswith(\"*.txt\"):       #specify certain files\n",
    "        listFiles.append(file)     #save the file's name in the list_files list\n",
    "        file_encoding = 'utf8'\n",
    "        with open(file, encoding=file_encoding, errors = 'ignore') as f:\n",
    "            flines = f.readlines() #reads over each line of the file\n",
    "            words = [] #creates an empty list named words\n",
    "            words_processed = []\n",
    "            filler_list = []\n",
    "            for line in flines: #for each line of the file\n",
    "                new_words = line.split() #splits the contents of each line according to white space. Now new_words\n",
    "                                     #contains all words within each line \n",
    "                    \n",
    "            words += [word.lower() for word in new_words] #turns all characters to lower case\n",
    "            \n",
    "            for word in words:\n",
    "                if not word.startswith('[=') and not word.endswith(']'):\n",
    "                    words_processed.append(word)   #remove unwanted strings e.g. tuts, coughs. Keeps false starts & unknown words.\n",
    "            \n",
    "            denominator = len(words_processed) #calculate the length to normalise by\n",
    "                 \n",
    "            fillers = ['um', 'uum', 'umm', 'er', 'eer', 'uh', 'ah', 'ahh', 'hm', 'hmm', 'mm', 'erm', 'um.', 'uum.', 'umm.', 'er.', 'eer.', 'uh.', 'ah.', 'ahh.', 'hm.', 'hmm.', 'mm.', 'erm.']\n",
    "            \n",
    "            for word in words:\n",
    "                if word in fillers:\n",
    "                     filler_list.append(word)\n",
    "                        \n",
    "            n_fillers = len(filler_list)\n",
    "            \n",
    "            if n_fillers is not 0:\n",
    "                #list_fillers.append(n_fillers)\n",
    "                filler_ratio = n_fillers/denominator\n",
    "                list_filler_ratio.append(filler_ratio)\n",
    "                \n",
    "            else:\n",
    "                #list_fillers.append('0')\n",
    "                list_filler_ratio.append('0')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Calculate number and ratio of pauses, false starts and 'thing' words\n",
    "\n",
    "listFiles = []           #create an empty list named list_files\n",
    "list_pause_ratio = []\n",
    "list_false_ratio = []\n",
    "list_thing_ratio = [] #n.b. 'things' should be calculated on processed texts, not unprocessed\n",
    "list_pauses = []\n",
    "list_falses = []\n",
    "list_things = [] #n.b. 'things' should be calculated on processed texts, not unprocessed\n",
    "\n",
    "for file in glob.glob(os.path.join(path, '*.txt')):      #for every file in the path\n",
    "    #if file.endswith(\"*.txt\"):       #specify certain files\n",
    "        listFiles.append(file)     #save the file's name in the list_files list\n",
    "        file_encoding = 'utf8'\n",
    "        with open(file, encoding=file_encoding, errors = 'ignore') as f:\n",
    "            flines = f.readlines() #reads over each line of the file\n",
    "            words = [] #creates an empty list named words\n",
    "            words_processed = []\n",
    "            pause_list = []\n",
    "            false_list = []\n",
    "            thing_list = []\n",
    "            for line in flines: #for each line of the file\n",
    "                new_words = line.split() #splits the contents of each line according to white space. Now new_words\n",
    "                                     #contains all words within each line \n",
    "                    \n",
    "            words += [word.lower() for word in new_words] #turns all characters to lower case\n",
    "            \n",
    "            for word in words:\n",
    "                if not word.startswith('[=') and not word.endswith(']'):\n",
    "                    words_processed.append(word)   #remove unwanted strings e.g. tuts, coughs. Keeps false starts & unknown words.\n",
    "            \n",
    "            denominator = len(words_processed) #calculate the length og this to normalise by\n",
    "            \n",
    "            \n",
    "            for word in words:\n",
    "                if word.endswith('..') or word.endswith('...'):\n",
    "                    pause_list.append(word)\n",
    "                    \n",
    "            n_pauses = len(pause_list)\n",
    "                    \n",
    "            if n_pauses is not 0:\n",
    "                #list_pauses.append(n_pauses)\n",
    "                pause_ratio = n_pauses/denominator\n",
    "                list_pause_ratio.append(pause_ratio)\n",
    "                    \n",
    "            else:\n",
    "                #list_pauses.append('0')\n",
    "                list_pause_ratio.append('0')\n",
    "                \n",
    "            for word in words:\n",
    "                if word.endswith('=') or word.endswith('=.'):\n",
    "                    false_list.append(word)\n",
    "                    \n",
    "            n_false = len(false_list)\n",
    "                    \n",
    "            if n_false is not 0:\n",
    "                #list_falses.append(n_false)\n",
    "                false_ratio = n_false/denominator\n",
    "                list_false_ratio.append(false_ratio)\n",
    "                    \n",
    "            else:\n",
    "                #list_falses.append('0')\n",
    "                list_false_ratio.append('0')\n",
    "                \n",
    "            things = ['thing', 'something', 'anything', 'thingy', 'things', 'thing.', 'something.', 'anything.', 'thingy.', 'things.']\n",
    "                \n",
    "            for word in words:\n",
    "                if word in things:\n",
    "                    thing_list.append(word)\n",
    "                    \n",
    "            n_thing = len(thing_list)\n",
    "                   \n",
    "            if n_thing is not 0:\n",
    "                #list_things.append(n_thing)\n",
    "                thing_ratio = n_thing/denominator\n",
    "                list_thing_ratio.append(thing_ratio)\n",
    "              \n",
    "            else:\n",
    "                #list_things.append('0')\n",
    "                list_thing_ratio.append('0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
